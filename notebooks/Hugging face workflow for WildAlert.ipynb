{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f71b126",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import datetime\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "print(start)\n",
    "import os as os\n",
    "\n",
    "os.chdir(\"C:/Users/prana/Desktop/directory/WildAlertModels/\")\n",
    "# os.chdir('/home/falco/Desktop/directory/Syndrome_classifier_trainer')\n",
    "data_path = \"C:/Users/prana/Desktop/directory/WildAlertModels/data/\"\n",
    "# data_path = '/home/falco/Desktop/directory/Syndrome_classifier_trainer/data'\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "import datetime\n",
    "import os\n",
    "import pickle\n",
    "from math import ceil\n",
    "\n",
    "import app\n",
    "import config\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import preprocess\n",
    "import simplejson as json\n",
    "from huggingface_hub import login\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from textblob import TextBlob\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from WRMDpy import Syndrome as Syndrome\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential,Model\n",
    "# from tensorflow.keras.layers import Dense, LSTM, Embedding,Dropout,SpatialDropout1D,Conv1D,MaxPooling1D,GRU,BatchNormalization\n",
    "# from tensorflow.keras.layers import Input,Bidirectional,GlobalAveragePooling1D,GlobalMaxPooling1D,concatenate,LeakyReLU\n",
    "# from tensorflow.keras import regularizers\n",
    "# from tensorflow.keras import backend as K\n",
    "# from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "# import tensorflow as tf\n",
    "# print(\"tensorflow version \", tf.__version__)\n",
    "\n",
    "# import keras\n",
    "# print(\"keras version \",keras.__version__)\n",
    "# import keras.callbacks\n",
    "# from keras.preprocessing.text import Tokenizer\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "# from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "login(token=None)\n",
    "\n",
    "plt.style.use(\"fivethirtyeight\")\n",
    "plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "plt.rcParams[\"font.family\"] = \"serif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2c5c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "path1 = \"https://www.wrmd.org/api/v2/ml/training-dataset/clinical-classifications\"\n",
    "# path1 = 'API/link/TrainingData'\n",
    "raw_data = json.loads(requests.get(path1).text)\n",
    "raw_data = pd.DataFrame(raw_data)\n",
    "cond = raw_data.terms.apply(pd.Series)\n",
    "cond.columns = [\"c1\", \"c2\", \"c3\", \"c4\", \"c5\"]\n",
    "raw_data = pd.concat([raw_data, cond], axis=1)\n",
    "raw_data[\"condition_predict\"] = raw_data.c1\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88621769-a796-4503-b1fb-9391af4c63e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c737c2-bc76-40bd-b5f4-0578118beeb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb74b50d-0465-4b94-8d0c-f8e95fd392ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "df = raw_data\n",
    "REPLACE_BY_SPACE_RE = re.compile(\"[/(){}\\[\\]\\|@,;]\")\n",
    "BAD_SYMBOLS_RE = re.compile(\"[^0-9a-z #+_]\")\n",
    "STOPWORDS = set(stopwords.words(\"english\"))\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    text: a string\n",
    "\n",
    "    return: modified initial string\n",
    "    \"\"\"\n",
    "    text = text.lower()  # lowercase text\n",
    "    text = REPLACE_BY_SPACE_RE.sub(\n",
    "        \" \", text\n",
    "    )  # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n",
    "    text = BAD_SYMBOLS_RE.sub(\n",
    "        \"\", text\n",
    "    )  # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing.\n",
    "    text = text.replace(\"x\", \"\")\n",
    "    #    text = re.sub(r'\\W+', '', text)\n",
    "    text = \" \".join(\n",
    "        word for word in text.split() if word not in STOPWORDS\n",
    "    )  # remove stopwors from text\n",
    "    return text\n",
    "\n",
    "\n",
    "df[\"text_clean\"] = df[\"text\"].apply(clean_text)\n",
    "df[\"text_clean\"] = df[\"text_clean\"].str.replace(\"\\d+\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76432e4b-75c1-4a86-ac57-eb5317ec0fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text_clean\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb2a97f-b9bb-4156-bf58-13c9c93f1fd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b66391-a7cf-42f5-802e-3b6d17414413",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a22ab65b",
   "metadata": {},
   "source": [
    "### creating dictionary similar to imdb dataset\n",
    "* Only one label : `condition_predict`\n",
    "* text column as predictor: `text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbe2b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_dict = df[[\"text_clean\", \"condition_predict\"]].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d08d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_dict[\"text_clean\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c766e029",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0f1578",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3c8e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(df, text_column):\n",
    "    return df[\"text_clean\"].apply(lambda x: tokenizer.encode(x, truncation=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a8f2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_wrmd = tokenize_text(raw_data, \"text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d49f472-413d-4211-bce8-45b93c21583b",
   "metadata": {},
   "source": [
    "Now create a batch of examples using `DataCollatorWithPadding`. Itâ€™s more efficient to dynamically pad the sentences to the longest length in a batch during collation, instead of padding the whole dataset to the maximum length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff99a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4bd9b2-0b52-4187-9de5-2f8354932094",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1973e16a-2169-4e7b-af86-ae7637479efd",
   "metadata": {},
   "source": [
    "Including a metric during training is often helpful for evaluating your modelâ€™s performance. You can quickly load a evaluation method with the ðŸ¤— Evaluate library. For this task, load the accuracy metric (see the ðŸ¤— Evaluate quick tour to learn more about how to load and compute a metric):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b5a5fc-1128-4fc4-83cf-979310a936e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10c93ea-7526-4067-888a-ff45aa412cc8",
   "metadata": {},
   "source": [
    "Then create a function that passes your predictions and labels to compute to calculate the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430ec474-8740-4479-9942-749ec5567942",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfe30ed-e041-4ee2-8cd6-c9b78379d677",
   "metadata": {},
   "source": [
    "### Label dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a495fcea-9fc5-4b51-bbc3-c634eea98642",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = raw_data.condition_predict.unique().tolist()\n",
    "values = list(np.arange(len(conditions)))\n",
    "values = [int(x) for x in values]\n",
    "label2id = dict(zip(conditions, values))\n",
    "print(label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4768cba4-3b32-492b-97ab-d71b1dbf6214",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {v: k for k, v in label2id.items()}\n",
    "print(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d473539-c4c7-458a-bb41-cc2eeba42d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(conditions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddf6c44-c7a8-4b1e-831f-095c55a356b6",
   "metadata": {},
   "source": [
    "## Training Pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b695ea71-25fe-4bc2-ac51-ad1857761f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=len(conditions),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9c5e4a-3a75-43bb-85c7-8e54708da859",
   "metadata": {},
   "source": [
    "Define your training hyperparameters in TrainingArguments.  \n",
    "The only required parameter is output_dir which specifies where to save your model.   \n",
    "Youâ€™ll push this model to the Hub by setting `push_to_hub=True` (you need to be signed in to Hugging Face to upload your model).   \n",
    "At the end of each epoch, the Trainer will evaluate the accuracy and save the training checkpoint.  \n",
    "Pass the training arguments to Trainer along with the model, dataset, tokenizer, data collator, and compute_metrics function.  \n",
    "Call `train()` to finetune your model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e04122-d920-4128-9672-dca65fdc6198",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"my_awesome_model\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_wrmd,\n",
    "    eval_dataset=tokenized_wrmd,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bee66b5-7457-471b-aa31-1fda83479136",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_wrmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e29b0ae-ee2a-4003-b084-e5ce7c7167b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faba7bec-8fce-4c0e-8896-61f762ecbc20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d346b2c-ed15-40b7-88cb-46d14e606aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c04783-b498-49a0-bdc5-a28946b690bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c9ff38-6c4b-47cc-a189-e898dfe29430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8c3857-0100-4981-b646-78c4fd335af9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96856494-429a-479b-bd02-d26a4d72e129",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4736b0a7-ade7-4ad4-aad4-b6c32cb906ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8712f3-2186-4c4d-8bcb-14d6f9c783d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
